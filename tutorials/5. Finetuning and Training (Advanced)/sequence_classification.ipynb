{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Sequence Classifier Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptnlp import EasyDocumentEmbeddings, SequenceClassifierTrainer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Initialize corpus, output directory for the model, and document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "May need a couple moments to instantiate...\n",
      "RNN embeddings loaded\n"
     ]
    }
   ],
   "source": [
    "corpus = \"Path/to/data/directory\" \n",
    "OUTPUT_DIR = \"Path/to/model/output/directory\" \n",
    "doc_embeddings = EasyDocumentEmbeddings(\"bert-base-cased\", methods = [\"rnn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Initialize Sequence Classification Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-03 17:24:41,190 Reading data from ../../development/data/trec_6\n",
      "2020-02-03 17:24:41,191 Train: ../../development/data/trec_6/train.csv\n",
      "2020-02-03 17:24:41,191 Dev: ../../development/data/trec_6/dev.csv\n",
      "2020-02-03 17:24:41,192 Test: ../../development/data/trec_6/test.csv\n",
      "2020-02-03 17:24:42,331 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4907/4907 [00:00<00:00, 221391.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-03 17:24:42,356 [b'LOC', b'DESC', b'ENTY', b'HUM', b'NUM', b'ABBR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sc_configs = {\n",
    "              \"corpus\": corpus,\n",
    "              \"encoder\": doc_embeddings,\n",
    "              \"column_name_map\": {0: \"text\", 1: \"label\"},\n",
    "              \"corpus_in_memory\": True,\n",
    "              \"predictive_head\": \"flair\",\n",
    "             }\n",
    "sc_trainer = SequenceClassifierTrainer(**sc_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Find Learning Rate with automated LR finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5135612484362082e-08]\n",
      "[1.8620871366628676e-08]\n",
      "[2.2908676527677733e-08]\n",
      "[2.818382931264454e-08]\n",
      "[3.4673685045253164e-08]\n",
      "[4.265795188015927e-08]\n",
      "[5.2480746024977265e-08]\n",
      "[6.456542290346554e-08]\n",
      "[7.943282347242815e-08]\n",
      "[9.772372209558107e-08]\n",
      "[1.2022644346174127e-07]\n",
      "[1.4791083881682077e-07]\n",
      "[1.819700858609984e-07]\n",
      "[2.2387211385683393e-07]\n",
      "[2.754228703338167e-07]\n",
      "[3.3884415613920264e-07]\n",
      "[4.168693834703353e-07]\n",
      "[5.128613839913649e-07]\n",
      "[6.309573444801935e-07]\n",
      "[7.762471166286916e-07]\n",
      "[9.54992586021436e-07]\n",
      "[1.1748975549395298e-06]\n",
      "[1.4454397707459273e-06]\n",
      "[1.778279410038923e-06]\n",
      "[2.187761623949553e-06]\n",
      "[2.6915348039269168e-06]\n",
      "[3.311311214825913e-06]\n",
      "[4.0738027780411255e-06]\n",
      "[5.011872336272722e-06]\n",
      "[6.165950018614822e-06]\n",
      "[7.585775750291839e-06]\n",
      "[9.332543007969913e-06]\n",
      "[1.1481536214968832e-05]\n",
      "[1.4125375446227536e-05]\n",
      "[1.737800828749375e-05]\n",
      "[2.1379620895022316e-05]\n",
      "[2.6302679918953824e-05]\n",
      "[3.2359365692962836e-05]\n",
      "[3.981071705534974e-05]\n",
      "[4.8977881936844595e-05]\n",
      "[6.025595860743576e-05]\n",
      "[7.413102413009174e-05]\n",
      "[9.120108393559098e-05]\n",
      "[0.00011220184543019637]\n",
      "[0.00013803842646028855]\n",
      "[0.00016982436524617435]\n",
      "[0.00020892961308540387]\n",
      "[0.00025703957827688637]\n",
      "[0.00031622776601683794]\n",
      "[0.0003890451449942807]\n",
      "[0.00047863009232263854]\n",
      "[0.0005888436553555893]\n",
      "[0.0007244359600749906]\n",
      "[0.0008912509381337464]\n",
      "[0.0010964781961431862]\n",
      "[0.001348962882591652]\n",
      "[0.0016595869074375593]\n",
      "[0.002041737944669528]\n",
      "[0.002511886431509579]\n",
      "[0.00309029543251359]\n",
      "[0.003801893963205612]\n",
      "[0.004677351412871982]\n",
      "[0.005754399373371571]\n",
      "[0.007079457843841382]\n",
      "[0.008709635899560813]\n",
      "[0.010715193052376074]\n",
      "[0.013182567385564083]\n",
      "[0.016218100973589285]\n",
      "[0.019952623149688778]\n",
      "[0.024547089156850287]\n",
      "[0.030199517204020147]\n",
      "[0.03715352290971724]\n",
      "[0.0457088189614875]\n",
      "[0.05623413251903491]\n",
      "[0.06918309709189367]\n",
      "[0.08511380382023769]\n",
      "[0.10471285480509002]\n",
      "[0.1288249551693135]\n",
      "[0.1584893192461115]\n",
      "[0.19498445997580477]\n",
      "[0.2398832919019488]\n",
      "[0.29512092266663836]\n",
      "[0.3630780547701011]\n",
      "[0.446683592150963]\n",
      "[0.5495408738576244]\n",
      "[0.6760829753919818]\n",
      "[0.8317637711026711]\n",
      "[1.0232929922807545]\n",
      "[1.2589254117941677]\n",
      "2020-02-03 17:22:07,001 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-03 17:22:07,002 loss diverged - stopping early!\n",
      "2020-02-03 17:22:07,018 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-03 17:22:07,018 learning rate finder finished - plot resources/taggers/bert-base-cased-control-trec_6/learning_rate.tsv\n",
      "2020-02-03 17:22:07,019 ----------------------------------------------------------------------------------------------------\n",
      "Learning_rate plots are saved in resources/taggers/bert-base-cased-control-trec_6/learning_rate.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Learning Rate 0.013182567385564083\n"
     ]
    }
   ],
   "source": [
    "sc_lr_configs = {\n",
    "        \"output_dir\": OUTPUT_DIR,\n",
    "        \"start_learning_rate\": 1e-8,\n",
    "        \"end_learning_rate\": 10,\n",
    "        \"iterations\": 100,\n",
    "        \"mini_batch_size\": 32,\n",
    "        \"stop_early\": True,\n",
    "        \"smoothing_factor\": 0.8,\n",
    "        \"plot_learning_rate\": True,\n",
    "}\n",
    "learning_rate = sc_trainer.find_learning_rate(**sc_lr_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train Sequence Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-03 17:22:48,895 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-03 17:22:48,898 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): BertEmbeddings(\n",
      "        (model): BertModel(\n",
      "          (embeddings): BertEmbeddings(\n",
      "            (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
      "            (position_embeddings): Embedding(512, 768)\n",
      "            (token_type_embeddings): Embedding(2, 768)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (encoder): BertEncoder(\n",
      "            (layer): ModuleList(\n",
      "              (0): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (1): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (2): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (3): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (4): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (5): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (6): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (7): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (8): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (9): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (10): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (11): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (pooler): BertPooler(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (activation): Tanh()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=3072, out_features=256, bias=True)\n",
      "    (rnn): GRU(256, 512, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=6, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2020-02-03 17:22:48,899 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-03 17:22:48,899 Corpus: \"Corpus: 4907 train + 545 dev + 500 test sentences\"\n",
      "2020-02-03 17:22:48,900 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-03 17:22:48,900 Parameters:\n",
      "2020-02-03 17:22:48,901  - learning_rate: \"0.013182567385564083\"\n",
      "2020-02-03 17:22:48,902  - mini_batch_size: \"32\"\n",
      "2020-02-03 17:22:48,903  - patience: \"5\"\n",
      "2020-02-03 17:22:48,903  - anneal_factor: \"0.5\"\n",
      "2020-02-03 17:22:48,904  - max_epochs: \"150\"\n",
      "2020-02-03 17:22:48,905  - shuffle: \"True\"\n",
      "2020-02-03 17:22:48,905  - train_with_dev: \"False\"\n",
      "2020-02-03 17:22:48,906  - batch_growth_annealing: \"False\"\n",
      "2020-02-03 17:22:48,907 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-03 17:22:48,908 Model training base path: \"resources/taggers/bert-base-cased-control-trec_6\"\n",
      "2020-02-03 17:22:48,909 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-03 17:22:48,909 Device: cuda:0\n",
      "2020-02-03 17:22:48,910 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-03 17:22:48,910 Embeddings storage mode: cpu\n",
      "2020-02-03 17:22:48,912 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-03 17:22:50,491 epoch 1 - iter 15/154 - loss 2.00981095 - samples/sec: 304.57\n",
      "2020-02-03 17:22:52,315 epoch 1 - iter 30/154 - loss 2.02736150 - samples/sec: 292.15\n",
      "2020-02-03 17:22:54,122 epoch 1 - iter 45/154 - loss 1.99382852 - samples/sec: 291.62\n",
      "2020-02-03 17:22:55,914 epoch 1 - iter 60/154 - loss 1.97336937 - samples/sec: 293.72\n",
      "2020-02-03 17:22:57,669 epoch 1 - iter 75/154 - loss 1.95729289 - samples/sec: 300.52\n",
      "2020-02-03 17:22:59,425 epoch 1 - iter 90/154 - loss 1.93891455 - samples/sec: 300.83\n",
      "2020-02-03 17:23:01,225 epoch 1 - iter 105/154 - loss 1.92440566 - samples/sec: 292.66\n",
      "2020-02-03 17:23:03,045 epoch 1 - iter 120/154 - loss 1.90464098 - samples/sec: 288.93\n",
      "2020-02-03 17:23:04,834 epoch 1 - iter 135/154 - loss 1.89684358 - samples/sec: 295.28\n",
      "2020-02-03 17:23:06,658 epoch 1 - iter 150/154 - loss 1.88469125 - samples/sec: 288.04\n",
      "2020-02-03 17:23:07,214 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-03 17:23:07,215 EPOCH 1 done: loss 1.8819 - lr 0.0132\n",
      "2020-02-03 17:23:08,933 DEV : loss 1.6651488542556763 - score 0.2312\n",
      "2020-02-03 17:23:08,947 BAD EPOCHS (no improvement): 0\n",
      "2020-02-03 17:23:10,732 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-03 17:23:11,105 epoch 2 - iter 15/154 - loss 1.78857572 - samples/sec: 1300.54\n",
      "2020-02-03 17:23:11,628 epoch 2 - iter 30/154 - loss 1.77649213 - samples/sec: 1321.50\n",
      "2020-02-03 17:23:12,160 epoch 2 - iter 45/154 - loss 1.76295167 - samples/sec: 1287.70\n",
      "2020-02-03 17:23:12,684 epoch 2 - iter 60/154 - loss 1.74197326 - samples/sec: 1313.56\n",
      "2020-02-03 17:23:13,198 epoch 2 - iter 75/154 - loss 1.73087422 - samples/sec: 1347.78\n",
      "2020-02-03 17:23:13,716 epoch 2 - iter 90/154 - loss 1.72299677 - samples/sec: 1334.74\n",
      "2020-02-03 17:23:14,244 epoch 2 - iter 105/154 - loss 1.71684670 - samples/sec: 1303.79\n",
      "2020-02-03 17:23:14,769 epoch 2 - iter 120/154 - loss 1.69854791 - samples/sec: 1314.84\n",
      "2020-02-03 17:23:15,298 epoch 2 - iter 135/154 - loss 1.68512577 - samples/sec: 1297.19\n",
      "2020-02-03 17:23:15,833 epoch 2 - iter 150/154 - loss 1.67539076 - samples/sec: 1277.62\n",
      "2020-02-03 17:23:16,081 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-03 17:23:16,082 EPOCH 2 done: loss 1.6693 - lr 0.0132\n",
      "2020-02-03 17:23:16,395 DEV : loss 1.6593389511108398 - score 0.2202\n",
      "2020-02-03 17:23:16,409 BAD EPOCHS (no improvement): 1\n",
      "2020-02-03 17:23:16,410 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-03 17:23:16,782 epoch 3 - iter 15/154 - loss 1.52451433 - samples/sec: 1297.70\n",
      "2020-02-03 17:23:17,312 epoch 3 - iter 30/154 - loss 1.53747180 - samples/sec: 1298.11\n",
      "2020-02-03 17:23:17,842 epoch 3 - iter 45/154 - loss 1.52053969 - samples/sec: 1297.11\n",
      "2020-02-03 17:23:18,365 epoch 3 - iter 60/154 - loss 1.50201139 - samples/sec: 1317.51\n",
      "2020-02-03 17:23:18,889 epoch 3 - iter 75/154 - loss 1.48467275 - samples/sec: 1319.71\n",
      "2020-02-03 17:23:19,414 epoch 3 - iter 90/154 - loss 1.49581883 - samples/sec: 1316.31\n",
      "2020-02-03 17:23:19,937 epoch 3 - iter 105/154 - loss 1.47902137 - samples/sec: 1317.93\n",
      "2020-02-03 17:23:20,461 epoch 3 - iter 120/154 - loss 1.47042264 - samples/sec: 1316.24\n",
      "2020-02-03 17:23:20,984 epoch 3 - iter 135/154 - loss 1.46099674 - samples/sec: 1316.33\n",
      "2020-02-03 17:23:21,510 epoch 3 - iter 150/154 - loss 1.44715818 - samples/sec: 1310.72\n",
      "2020-02-03 17:23:21,764 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-03 17:23:21,765 EPOCH 3 done: loss 1.4434 - lr 0.0132\n",
      "2020-02-03 17:23:22,077 DEV : loss 1.4826014041900635 - score 0.4165\n",
      "2020-02-03 17:23:22,091 BAD EPOCHS (no improvement): 0\n",
      "2020-02-03 17:23:23,624 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-03 17:23:23,999 epoch 4 - iter 15/154 - loss 1.33261875 - samples/sec: 1292.75\n",
      "2020-02-03 17:23:24,517 epoch 4 - iter 30/154 - loss 1.30822272 - samples/sec: 1333.87\n",
      "2020-02-03 17:23:25,045 epoch 4 - iter 45/154 - loss 1.31436030 - samples/sec: 1308.35\n",
      "2020-02-03 17:23:25,576 epoch 4 - iter 60/154 - loss 1.32304785 - samples/sec: 1290.78\n",
      "2020-02-03 17:23:26,114 epoch 4 - iter 75/154 - loss 1.32496640 - samples/sec: 1265.61\n",
      "2020-02-03 17:23:26,641 epoch 4 - iter 90/154 - loss 1.31515482 - samples/sec: 1305.82\n",
      "2020-02-03 17:23:27,164 epoch 4 - iter 105/154 - loss 1.30816143 - samples/sec: 1321.16\n",
      "2020-02-03 17:23:27,692 epoch 4 - iter 120/154 - loss 1.29619225 - samples/sec: 1298.48\n",
      "2020-02-03 17:23:28,219 epoch 4 - iter 135/154 - loss 1.28524434 - samples/sec: 1305.41\n",
      "2020-02-03 17:23:28,748 epoch 4 - iter 150/154 - loss 1.27717942 - samples/sec: 1299.45\n",
      "2020-02-03 17:23:28,997 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-03 17:23:28,998 EPOCH 4 done: loss 1.2723 - lr 0.0132\n",
      "2020-02-03 17:23:29,311 DEV : loss 1.3954064846038818 - score 0.3908\n",
      "2020-02-03 17:23:29,325 BAD EPOCHS (no improvement): 1\n",
      "2020-02-03 17:23:29,325 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-03 17:23:29,698 epoch 5 - iter 15/154 - loss 1.19402444 - samples/sec: 1298.26\n",
      "2020-02-03 17:23:30,220 epoch 5 - iter 30/154 - loss 1.18995562 - samples/sec: 1321.40\n",
      "2020-02-03 17:23:30,750 epoch 5 - iter 45/154 - loss 1.14993329 - samples/sec: 1297.81\n",
      "2020-02-03 17:23:31,277 epoch 5 - iter 60/154 - loss 1.14937518 - samples/sec: 1302.90\n",
      "2020-02-03 17:23:31,811 epoch 5 - iter 75/154 - loss 1.13519803 - samples/sec: 1284.12\n",
      "2020-02-03 17:23:32,332 epoch 5 - iter 90/154 - loss 1.12942576 - samples/sec: 1328.30\n",
      "2020-02-03 17:23:32,864 epoch 5 - iter 105/154 - loss 1.12505102 - samples/sec: 1282.26\n",
      "2020-02-03 17:23:33,385 epoch 5 - iter 120/154 - loss 1.12683471 - samples/sec: 1329.34\n",
      "2020-02-03 17:23:33,909 epoch 5 - iter 135/154 - loss 1.11711226 - samples/sec: 1315.40\n",
      "2020-02-03 17:23:34,446 epoch 5 - iter 150/154 - loss 1.11457481 - samples/sec: 1272.09\n",
      "2020-02-03 17:23:34,699 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-03 17:23:34,700 EPOCH 5 done: loss 1.1145 - lr 0.0132\n",
      "2020-02-03 17:23:35,012 DEV : loss 1.2109445333480835 - score 0.556\n",
      "2020-02-03 17:23:35,026 BAD EPOCHS (no improvement): 0\n",
      "2020-02-03 17:23:37,083 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-03 17:23:37,471 epoch 6 - iter 15/154 - loss 1.08163389 - samples/sec: 1253.23\n",
      "2020-02-03 17:23:37,998 epoch 6 - iter 30/154 - loss 1.05942845 - samples/sec: 1305.77\n",
      "2020-02-03 17:23:38,523 epoch 6 - iter 45/154 - loss 1.06039954 - samples/sec: 1310.66\n",
      "2020-02-03 17:23:39,048 epoch 6 - iter 60/154 - loss 1.04645513 - samples/sec: 1313.66\n",
      "2020-02-03 17:23:39,575 epoch 6 - iter 75/154 - loss 1.01291083 - samples/sec: 1310.23\n",
      "2020-02-03 17:23:40,105 epoch 6 - iter 90/154 - loss 1.00261579 - samples/sec: 1291.86\n",
      "2020-02-03 17:23:40,636 epoch 6 - iter 105/154 - loss 0.99945184 - samples/sec: 1296.01\n",
      "2020-02-03 17:23:41,167 epoch 6 - iter 120/154 - loss 1.00116350 - samples/sec: 1295.68\n",
      "2020-02-03 17:23:41,692 epoch 6 - iter 135/154 - loss 1.00184596 - samples/sec: 1313.31\n",
      "2020-02-03 17:23:42,229 epoch 6 - iter 150/154 - loss 0.99653594 - samples/sec: 1273.16\n",
      "2020-02-03 17:23:42,480 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-03 17:23:42,481 EPOCH 6 done: loss 0.9923 - lr 0.0132\n",
      "2020-02-03 17:23:42,796 DEV : loss 1.2490580081939697 - score 0.4606\n",
      "2020-02-03 17:23:42,810 BAD EPOCHS (no improvement): 1\n",
      "2020-02-03 17:23:42,811 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-03 17:23:43,185 epoch 7 - iter 15/154 - loss 0.91958833 - samples/sec: 1295.68\n",
      "2020-02-03 17:23:43,719 epoch 7 - iter 30/154 - loss 0.92864351 - samples/sec: 1281.32\n",
      "2020-02-03 17:23:44,242 epoch 7 - iter 45/154 - loss 0.90553544 - samples/sec: 1319.94\n",
      "2020-02-03 17:23:44,776 epoch 7 - iter 60/154 - loss 0.89058681 - samples/sec: 1282.75\n",
      "2020-02-03 17:23:45,304 epoch 7 - iter 75/154 - loss 0.87496053 - samples/sec: 1307.02\n",
      "2020-02-03 17:23:45,842 epoch 7 - iter 90/154 - loss 0.87079627 - samples/sec: 1272.74\n",
      "2020-02-03 17:23:46,370 epoch 7 - iter 105/154 - loss 0.86684524 - samples/sec: 1301.86\n",
      "2020-02-03 17:23:46,895 epoch 7 - iter 120/154 - loss 0.87580637 - samples/sec: 1309.93\n",
      "2020-02-03 17:23:47,428 epoch 7 - iter 135/154 - loss 0.86944242 - samples/sec: 1289.44\n",
      "2020-02-03 17:23:47,965 epoch 7 - iter 150/154 - loss 0.85849801 - samples/sec: 1268.89\n",
      "2020-02-03 17:23:48,223 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-03 17:23:48,224 EPOCH 7 done: loss 0.8610 - lr 0.0132\n",
      "2020-02-03 17:23:48,538 DEV : loss 0.8188268542289734 - score 0.7064\n",
      "2020-02-03 17:23:48,551 BAD EPOCHS (no improvement): 0\n",
      "2020-02-03 17:23:50,088 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-03 17:23:50,464 epoch 8 - iter 15/154 - loss 0.78822307 - samples/sec: 1287.24\n",
      "2020-02-03 17:23:50,991 epoch 8 - iter 30/154 - loss 0.77578991 - samples/sec: 1311.71\n",
      "2020-02-03 17:23:51,518 epoch 8 - iter 45/154 - loss 0.77604803 - samples/sec: 1305.28\n",
      "2020-02-03 17:23:52,049 epoch 8 - iter 60/154 - loss 0.76186523 - samples/sec: 1293.90\n",
      "2020-02-03 17:23:52,576 epoch 8 - iter 75/154 - loss 0.75778368 - samples/sec: 1303.52\n",
      "2020-02-03 17:23:53,098 epoch 8 - iter 90/154 - loss 0.75677341 - samples/sec: 1323.57\n",
      "2020-02-03 17:23:53,622 epoch 8 - iter 105/154 - loss 0.75670039 - samples/sec: 1312.83\n",
      "2020-02-03 17:23:54,147 epoch 8 - iter 120/154 - loss 0.75643629 - samples/sec: 1308.46\n",
      "2020-02-03 17:23:54,674 epoch 8 - iter 135/154 - loss 0.75320344 - samples/sec: 1299.96\n",
      "2020-02-03 17:23:55,198 epoch 8 - iter 150/154 - loss 0.74946543 - samples/sec: 1310.26\n",
      "2020-02-03 17:23:55,446 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-03 17:23:55,447 EPOCH 8 done: loss 0.7475 - lr 0.0132\n",
      "2020-02-03 17:23:55,758 DEV : loss 0.8468999862670898 - score 0.6881\n",
      "2020-02-03 17:23:55,771 BAD EPOCHS (no improvement): 1\n",
      "2020-02-03 17:23:55,773 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-03 17:23:56,143 epoch 9 - iter 15/154 - loss 0.72217224 - samples/sec: 1305.52\n",
      "2020-02-03 17:23:56,664 epoch 9 - iter 30/154 - loss 0.70195340 - samples/sec: 1322.20\n",
      "2020-02-03 17:23:57,199 epoch 9 - iter 45/154 - loss 0.67800412 - samples/sec: 1276.29\n",
      "2020-02-03 17:23:57,717 epoch 9 - iter 60/154 - loss 0.65873645 - samples/sec: 1334.42\n",
      "2020-02-03 17:23:58,238 epoch 9 - iter 75/154 - loss 0.66853302 - samples/sec: 1323.62\n",
      "2020-02-03 17:23:58,767 epoch 9 - iter 90/154 - loss 0.67187519 - samples/sec: 1294.42\n",
      "2020-02-03 17:23:59,292 epoch 9 - iter 105/154 - loss 0.66947470 - samples/sec: 1311.35\n",
      "2020-02-03 17:23:59,817 epoch 9 - iter 120/154 - loss 0.66569851 - samples/sec: 1310.96\n",
      "2020-02-03 17:24:00,350 epoch 9 - iter 135/154 - loss 0.66144669 - samples/sec: 1278.49\n",
      "2020-02-03 17:24:00,877 epoch 9 - iter 150/154 - loss 0.64850918 - samples/sec: 1303.20\n",
      "2020-02-03 17:24:01,129 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-03 17:24:01,131 EPOCH 9 done: loss 0.6484 - lr 0.0132\n",
      "2020-02-03 17:24:01,448 DEV : loss 0.676243782043457 - score 0.7284\n",
      "2020-02-03 17:24:01,462 BAD EPOCHS (no improvement): 0\n",
      "2020-02-03 17:24:03,003 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-03 17:24:03,383 epoch 10 - iter 15/154 - loss 0.62201777 - samples/sec: 1276.80\n",
      "2020-02-03 17:24:03,916 epoch 10 - iter 30/154 - loss 0.61659100 - samples/sec: 1282.06\n",
      "2020-02-03 17:24:04,443 epoch 10 - iter 45/154 - loss 0.59766519 - samples/sec: 1304.54\n",
      "2020-02-03 17:24:04,970 epoch 10 - iter 60/154 - loss 0.59760259 - samples/sec: 1301.04\n",
      "2020-02-03 17:24:05,502 epoch 10 - iter 75/154 - loss 0.59561908 - samples/sec: 1286.98\n",
      "2020-02-03 17:24:06,019 epoch 10 - iter 90/154 - loss 0.59237055 - samples/sec: 1337.93\n",
      "2020-02-03 17:24:06,540 epoch 10 - iter 105/154 - loss 0.59235870 - samples/sec: 1321.39\n",
      "2020-02-03 17:24:07,066 epoch 10 - iter 120/154 - loss 0.57761797 - samples/sec: 1305.27\n",
      "2020-02-03 17:24:07,588 epoch 10 - iter 135/154 - loss 0.57660196 - samples/sec: 1322.94\n",
      "2020-02-03 17:24:08,116 epoch 10 - iter 150/154 - loss 0.57698319 - samples/sec: 1297.01\n",
      "2020-02-03 17:24:08,367 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-03 17:24:08,368 EPOCH 10 done: loss 0.5768 - lr 0.0132\n",
      "2020-02-03 17:24:08,681 DEV : loss 0.4618481695652008 - score 0.8459\n",
      "2020-02-03 17:24:08,695 BAD EPOCHS (no improvement): 0\n",
      "2020-02-03 17:24:10,232 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-03 17:24:10,614 epoch 11 - iter 15/154 - loss 0.56491884 - samples/sec: 1269.04\n",
      "2020-02-03 17:24:11,140 epoch 11 - iter 30/154 - loss 0.54027900 - samples/sec: 1305.77\n",
      "2020-02-03 17:24:11,660 epoch 11 - iter 45/154 - loss 0.54218909 - samples/sec: 1329.61\n",
      "2020-02-03 17:24:12,183 epoch 11 - iter 60/154 - loss 0.52460331 - samples/sec: 1318.64\n",
      "2020-02-03 17:24:12,713 epoch 11 - iter 75/154 - loss 0.51705905 - samples/sec: 1298.61\n",
      "2020-02-03 17:24:13,235 epoch 11 - iter 90/154 - loss 0.52064273 - samples/sec: 1317.84\n",
      "2020-02-03 17:24:13,762 epoch 11 - iter 105/154 - loss 0.50577083 - samples/sec: 1305.87\n",
      "2020-02-03 17:24:14,285 epoch 11 - iter 120/154 - loss 0.50715957 - samples/sec: 1320.67\n",
      "2020-02-03 17:24:14,808 epoch 11 - iter 135/154 - loss 0.51516161 - samples/sec: 1316.35\n",
      "2020-02-03 17:24:15,342 epoch 11 - iter 150/154 - loss 0.51968253 - samples/sec: 1281.56\n",
      "2020-02-03 17:24:15,594 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-03 17:24:15,594 EPOCH 11 done: loss 0.5184 - lr 0.0132\n",
      "2020-02-03 17:24:15,907 DEV : loss 0.48296573758125305 - score 0.8257\n",
      "2020-02-03 17:24:15,921 BAD EPOCHS (no improvement): 1\n",
      "2020-02-03 17:24:15,923 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-03 17:24:16,295 epoch 12 - iter 15/154 - loss 0.50035683 - samples/sec: 1298.72\n",
      "2020-02-03 17:24:16,812 epoch 12 - iter 30/154 - loss 0.47189402 - samples/sec: 1338.12\n",
      "2020-02-03 17:24:17,344 epoch 12 - iter 45/154 - loss 0.45618302 - samples/sec: 1284.97\n",
      "2020-02-03 17:24:17,871 epoch 12 - iter 60/154 - loss 0.46401520 - samples/sec: 1301.36\n",
      "2020-02-03 17:24:18,393 epoch 12 - iter 75/154 - loss 0.47587990 - samples/sec: 1321.46\n",
      "2020-02-03 17:24:18,916 epoch 12 - iter 90/154 - loss 0.46481342 - samples/sec: 1317.41\n",
      "2020-02-03 17:24:19,443 epoch 12 - iter 105/154 - loss 0.47376057 - samples/sec: 1305.55\n",
      "2020-02-03 17:24:19,966 epoch 12 - iter 120/154 - loss 0.47499431 - samples/sec: 1317.92\n",
      "2020-02-03 17:24:20,486 epoch 12 - iter 135/154 - loss 0.46965439 - samples/sec: 1327.01\n",
      "2020-02-03 17:24:21,013 epoch 12 - iter 150/154 - loss 0.48014564 - samples/sec: 1302.47\n",
      "2020-02-03 17:24:21,262 ----------------------------------------------------------------------------------------------------\n",
      "2020-02-03 17:24:21,263 EPOCH 12 done: loss 0.4779 - lr 0.0132\n"
     ]
    }
   ],
   "source": [
    "sc_train_configs = {\n",
    "        \"output_dir\": OUTPUT_DIR,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"mini_batch_size\": 32,\n",
    "        \"anneal_factor\": 0.5,\n",
    "        \"patience\": 5,\n",
    "        \"max_epochs\": 150,\n",
    "        \"plot_weights\": False,\n",
    "        \"batch_growth_annealing\": False,\n",
    "}\n",
    "sc_trainer.train(**sc_train_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Load and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-03 17:25:22,688 loading file ../5. Finetuning and Training (Advanced)/resources/taggers/bert-base-cased-control-trec_6-finetuned/final-model.pt\n",
      "Label output:\n",
      "\n",
      "[LOC (0.9996310472488403)]\n"
     ]
    }
   ],
   "source": [
    "from adaptnlp import EasySequenceClassifier\n",
    "# Set example text and instantiate tagger instance\n",
    "example_text = '''Where was the Queen's wedding held? '''\n",
    "\n",
    "classifier = EasySequenceClassifier()\n",
    "\n",
    "sentences = classifier.tag_text(example_text, model_name_or_path=\"../5. Finetuning and Training (Advanced)/resources/taggers/bert-base-cased-control-trec_6-finetuned/final-model.pt\")\n",
    "print(\"Label output:\\n\")\n",
    "for sentence in sentences:\n",
    "    print(sentence.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Sequence Classifier on Finetuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"../../development/data/trec_6\"\n",
    "OUTPUT_DIR = \"./resources/taggers/bert-base-cased-control-trec_6-finetuned\"\n",
    "doc_embeddings = EasyDocumentEmbeddings(\"./resources/finetuned/bert-base-cased-trec_6\", methods = [\"rnn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_configs = {\n",
    "              \"corpus\": corpus,\n",
    "              \"encoder\": doc_embeddings,\n",
    "              \"column_name_map\": {0: \"text\", 1: \"label\"},\n",
    "              \"corpus_in_memory\": True,\n",
    "              \"predictive_head\": \"flair\",\n",
    "             }\n",
    "sc_trainer = SequenceClassifierTrainer(**sc_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_lr_configs = {\n",
    "        \"output_dir\": OUTPUT_DIR,\n",
    "        \"start_learning_rate\": 1e-8,\n",
    "        \"end_learning_rate\": 10,\n",
    "        \"iterations\": 100,\n",
    "        \"mini_batch_size\": 32,\n",
    "        \"stop_early\": True,\n",
    "        \"smoothing_factor\": 0.8,\n",
    "        \"plot_learning_rate\": True,\n",
    "}\n",
    "learning_rate = sc_trainer.find_learning_rate(**sc_lr_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_train_configs = {\n",
    "        \"output_dir\": OUTPUT_DIR,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"mini_batch_size\": 32,\n",
    "        \"anneal_factor\": 0.5,\n",
    "        \"patience\": 5,\n",
    "        \"max_epochs\": 150,\n",
    "        \"plot_weights\": False,\n",
    "        \"batch_growth_annealing\": False,\n",
    "}\n",
    "sc_trainer.train(**sc_train_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
